# Copyright 2020 The Trax Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# -*-Python-*-

import trax.models
import trax.data.inputs

include 'scientific_papers_reformer2.gin'

# TODO(wgaj): Add shuffling.
make_inputs.train_stream = [
  @train/data.TFDS(),
  @data.Tokenize(),
  @data.TruncateToLength(),
  @data.AppendValue(),
  @data.PadToLength(),
  @data.AddLossWeights(),
  @data.Batch()
]
train/data.TFDS.dataset_name = 'scientific_papers/arxiv:1.1.1'
train/data.TFDS.keys = ('article', 'abstract')
train/data.TFDS.train = True
data.Tokenize.vocab_file = '/placer/prod/home/brain-ogm-data-writer/spm/cc_all.32000/sentencepiece.model%fallback_radius=ANYWHERE'
data.Tokenize.keys = [0, 1]
data.Tokenize.vocab_type = 'sentencepiece'
data.TruncateToLength.len_map = {0: (15*1024-1, ), 1: (1024-1, )}
data.AppendValue.val = {0:[0], 1:[1]}
data.PadToLength.len_map = {0: 15*1024, 1: 1024}
data.PadToLength.pad_value = {0: 0, 1: 0}
data.Batch.batch_size = 32
data.AddLossWeights.id_to_mask = 0

make_inputs.eval_stream = [
  @eval/data.TFDS(),
  @data.Tokenize(),
  @data.TruncateToLength(),
  @data.AppendValue(),
  @data.PadToLength(),
  @data.AddLossWeights(),
  @data.Batch()
]
train/data.TFDS.dataset_name = 'scientific_papers/arxiv:1.1.1'
train/data.TFDS.keys = ('article', 'abstract')
train/data.TFDS.train = False

train.inputs = @trax.data.inputs.make_inputs
train.model = @trax.models.Reformer2
